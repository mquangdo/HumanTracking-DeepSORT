{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11126715,"sourceType":"datasetVersion","datasetId":6939117},{"sourceId":11077228,"sourceType":"datasetVersion","datasetId":6903871}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T12:48:55.881912Z","iopub.execute_input":"2025-03-24T12:48:55.882165Z","iopub.status.idle":"2025-03-24T12:48:56.487414Z","shell.execute_reply.started":"2025-03-24T12:48:55.882142Z","shell.execute_reply":"2025-03-24T12:48:56.486727Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.models import mobilenet_v2\nfrom torch import nn\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:16:02.582448Z","iopub.execute_input":"2025-03-24T13:16:02.582782Z","iopub.status.idle":"2025-03-24T13:16:02.586875Z","shell.execute_reply.started":"2025-03-24T13:16:02.582758Z","shell.execute_reply":"2025-03-24T13:16:02.586009Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:01:56.552660Z","iopub.execute_input":"2025-03-24T13:01:56.553009Z","iopub.status.idle":"2025-03-24T13:02:01.749649Z","shell.execute_reply.started":"2025-03-24T13:01:56.552980Z","shell.execute_reply":"2025-03-24T13:02:01.748552Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.95-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.95-py3-none-any.whl (949 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.95 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Needed functions","metadata":{}},{"cell_type":"code","source":"def extract_patches_from_detections(image, detections, target_size=(224, 224)):\n     \"\"\"\n    Extract images lying inside bounding boxs\n\n    Args:\n        image: An image or frame.\n        detections: the detections obtained by detector for the image.\n\n    Returns:\n        list: List of small images inside bbox\n    \"\"\"\n    \n    patches = []\n    \n    for det in detections:\n        # Lấy tọa độ bounding box: bb_left, bb_top, bb_width, bb_height\n        bb_left, bb_top, bb_width, bb_height = det[2:6].astype(np.int64)\n            \n        # Chuyển sang định dạng (x1, y1, x2, y2)\n        x1, y1 = bb_left, bb_top\n        x2, y2 = x1 + bb_width, y1 + bb_height\n            \n        # Giới hạn tọa độ trong kích thước ảnh\n        x1 = max(0, x1)\n        y1 = max(0, y1)\n        x2 = min(image.shape[1] - 1, x2)  # width\n        y2 = min(image.shape[0] - 1, y2)  # height\n            \n        patch = image[y1:y2, x1:x2]\n            \n        # Resize về target_size\n        patch = cv2.resize(patch, target_size[::-1])  \n            \n        patches.append(patch)\n    \n    return patches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T12:52:29.808151Z","iopub.execute_input":"2025-03-24T12:52:29.808452Z","iopub.status.idle":"2025-03-24T12:52:29.814374Z","shell.execute_reply.started":"2025-03-24T12:52:29.808431Z","shell.execute_reply":"2025-03-24T12:52:29.813460Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def extract_feature(model, img, device):\n    '''\n    Extract feature vector of an image\n\n    Args:\n        model: CNNs model for feature extracting\n        img: An image or frame.\n        device: cuda or cpu\n        \n    Returns:\n        torch.tensor: Feature vector of an image'''\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        img = torch.tensor(img).permute(2, 0, 1).float().unsqueeze(0).to(device)\n        return model(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:01:09.429468Z","iopub.execute_input":"2025-03-24T13:01:09.429779Z","iopub.status.idle":"2025-03-24T13:01:09.434076Z","shell.execute_reply.started":"2025-03-24T13:01:09.429753Z","shell.execute_reply":"2025-03-24T13:01:09.433257Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_model(device):\n    \n    model = mobilenet_v2(pretrained=True)\n    model.classifier = nn.Sequential(\n            nn.Dropout(p=0.2),\n            nn.Linear(1280, 128)  # trích xuất vector 128 chiều\n        )\n    model.eval()\n    model = model.to(device)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:01:32.996113Z","iopub.execute_input":"2025-03-24T13:01:32.996421Z","iopub.status.idle":"2025-03-24T13:01:33.000568Z","shell.execute_reply.started":"2025-03-24T13:01:32.996392Z","shell.execute_reply":"2025-03-24T13:01:32.999877Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def get_feature_file(model, folder_path, detections_path):\n    '''\n    Args:\n        folder_path: folder which contains images or frame of the video\n        detections_path: detections file path from the MOT challenge dataset\n    '''\n    mot_det = np.loadtxt(detections_path, delimiter=',')\n    my_features = []\n    # Duyệt qua tất cả file trong folder\n    frame_id = 1\n    for filename in sorted(os.listdir(folder_path)):\n        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Chỉ xử lý các file ảnh\n            image_path = os.path.join(folder_path, filename)\n            img = cv2.imread(image_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            detections = mot_det[mot_det[:, 0] == frame_id, :]\n            cropped_images = extract_patches_from_detections(img, detections,target_size=(224, 224))\n            for cropped_image in cropped_images:\n                feature = extract_feature(model, cropped_image, device)\n                my_features.append(feature.detach().cpu().numpy().ravel())\n            print(frame_id)\n        frame_id += 1\n    my_features = np.array(my_features)\n    new_features = np.hstack([mot_det, my_features])\n    np.save(folder_path.split('/')[6] + 'det', new_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:07:53.398115Z","iopub.execute_input":"2025-03-24T13:07:53.398416Z","iopub.status.idle":"2025-03-24T13:07:53.404495Z","shell.execute_reply.started":"2025-03-24T13:07:53.398397Z","shell.execute_reply":"2025-03-24T13:07:53.403615Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Reimplement functions for YOLO","metadata":{}},{"cell_type":"code","source":"def extract_patches_from_detections_yolo(image, detections, target_size=(224, 224)):\n    \n    patches = []\n    \n    for det in detections:\n        # Lấy tọa độ bounding box: bb_left, bb_top, bb_width, bb_height\n        x1, y1, x2, y2, conf = det.astype(np.int64)\n            \n        # ## Chuyển sang định dạng (x1, y1, x2, y2)\n        # x1, y1 = bb_left, bb_top\n        # x2, y2 = x1 + bb_width, y1 + bb_height\n            \n        # Giới hạn tọa độ trong kích thước ảnh\n        x1 = max(0, x1)\n        y1 = max(0, y1)\n        x2 = min(image.shape[1] - 1, x2)  # width\n        y2 = min(image.shape[0] - 1, y2)  # height\n            \n        patch = image[y1:y2, x1:x2]\n            \n        # Resize về target_size\n        patch = cv2.resize(patch, target_size[::-1])  # cv2 dùng (width, height)\n            \n        patches.append(patch)\n    \n    return patches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:18:38.403195Z","iopub.execute_input":"2025-03-24T13:18:38.403517Z","iopub.status.idle":"2025-03-24T13:18:38.408744Z","shell.execute_reply.started":"2025-03-24T13:18:38.403495Z","shell.execute_reply":"2025-03-24T13:18:38.407925Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def get_feature_file_yolo_detector(yolo, model, folder_path):\n    '''\n    Args:\n        yolo :light weight yolo model\n        model: CNNs model for feature extracting\n        folder_path: folder which contains images or frame of the video\n    '''\n    my_features = []\n    my_detections = []\n    my_frame_id = []\n    frame_id = 1\n    for filename in sorted(os.listdir(folder_path)):\n        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Chỉ xử lý các file ảnh\n            image_path = os.path.join(folder_path, filename)\n            # Mở và hiển thị ảnh bằng PIL\n            img = cv2.imread(image_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # detections = mot_det[mot_det[:, 0] == frame_id, :]\n            results = yolo(img)\n            detections = results[0].boxes.data.cpu().numpy()[:, :-1]\n            # detections = torch.cat([boxes.xyxy, boxes.conf.reshape(len(boxes.conf), -1)], dim=1).cpu().numpy()\n            my_detections.append(detections)\n            cropped_images = extract_patches_from_detections_yolo(img, detections,target_size=(224, 224))\n            for cropped_image in cropped_images:\n                feature = extract_feature(model, cropped_image, device)\n                my_features.append(feature.detach().cpu().numpy().ravel())\n                my_frame_id.append(frame_id)\n            print(frame_id)\n        frame_id += 1\n    \n    my_features = np.array(my_features)\n    my_frame_id = np.array(my_frame_id).reshape(len(my_frame_id),-1)\n    my_detections = np.vstack(my_detections)\n    my_detections[:, 2] -= my_detections[:, 0]\n    my_detections[:, 3] -= my_detections[:, 1]\n    minus_column = -np.ones((my_frame_id.shape[0], 1))\n    minus_matrix = -np.ones((my_frame_id.shape[0], 3))\n    result = np.hstack([my_frame_id, minus_column, my_detections, minus_matrix, my_features])\n    np.save('yolo' + folder_path.split('/')[6] + 'det', result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:40:12.874792Z","iopub.execute_input":"2025-03-24T13:40:12.875186Z","iopub.status.idle":"2025-03-24T13:40:12.882784Z","shell.execute_reply.started":"2025-03-24T13:40:12.875158Z","shell.execute_reply":"2025-03-24T13:40:12.881866Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def get_feature_file_from_video(yolo, model, video_path):\n    '''\n    Args:\n        yolo :light weight yolo model\n        model: CNNs model for feature extracting\n        video_path: path to video from MOT Challenge dataset\n    '''\n    my_features = []\n    my_detections = []\n    my_frame_id = []\n    \n    frame_id = 1\n    cap = cv2.VideoCapture(video_path)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n    \n        # Phát hiện bounding box bằng YOLOv8\n        results = yolo(frame)\n        detections = results[0].boxes.data.cpu().numpy()[:, :-1]  # [x_min, y_min, x_max, y_max, conf, cls]\n        my_detections.append(detections)\n    \n        cropped_images = extract_patches_from_detections_yolo(frame, detections,target_size=(224, 224))\n    \n        for cropped_imgs in cropped_images:\n            feature = extract_feature(model, cropped_imgs, device)\n            my_features.append(feature.detach().cpu().numpy().ravel())\n            my_frame_id.append(frame_id) \n        print(frame_id)\n        frame_id += 1\n    cap.release()\n\n    my_features = np.array(my_features)\n    my_frame_id = np.array(my_frame_id).reshape(len(my_frame_id),-1)\n    my_detections = np.vstack(my_detections)\n    my_detections[:, 2] -= my_detections[:, 0]\n    my_detections[:, 3] -= my_detections[:, 1]\n    my_detections *= 2\n    minus_column = -np.ones((my_frame_id.shape[0], 1))\n    minus_matrix = -np.ones((my_frame_id.shape[0], 3))\n    result = np.hstack([my_frame_id, minus_column, my_detections, minus_matrix, my_features])\n    np.save('yolo' + video_path.split('/')[3] + 'det', result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T14:05:06.369175Z","iopub.execute_input":"2025-03-24T14:05:06.369541Z","iopub.status.idle":"2025-03-24T14:05:06.376794Z","shell.execute_reply.started":"2025-03-24T14:05:06.369511Z","shell.execute_reply":"2025-03-24T14:05:06.375829Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"## Implement","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:09:48.104305Z","iopub.execute_input":"2025-03-24T13:09:48.104635Z","iopub.status.idle":"2025-03-24T13:09:48.160404Z","shell.execute_reply.started":"2025-03-24T13:09:48.104609Z","shell.execute_reply":"2025-03-24T13:09:48.159653Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"folder_path = '/kaggle/input/mot16-dataset/MOT16/train/MOT16-02/img1'\ndetections_path = '/kaggle/input/mot16-dataset/MOT16/train/MOT16-02/det/det.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:09:07.927986Z","iopub.execute_input":"2025-03-24T13:09:07.928296Z","iopub.status.idle":"2025-03-24T13:09:07.931806Z","shell.execute_reply.started":"2025-03-24T13:09:07.928274Z","shell.execute_reply":"2025-03-24T13:09:07.930947Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model = get_model(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:10:25.428692Z","iopub.execute_input":"2025-03-24T13:10:25.429027Z","iopub.status.idle":"2025-03-24T13:10:25.958375Z","shell.execute_reply.started":"2025-03-24T13:10:25.429001Z","shell.execute_reply":"2025-03-24T13:10:25.957670Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 143MB/s]\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"get_feature_file(model, folder_path, detections_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## YOLO","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\nyolo = YOLO('yolov8n.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:25:19.653549Z","iopub.execute_input":"2025-03-24T13:25:19.653943Z","iopub.status.idle":"2025-03-24T13:25:20.620100Z","shell.execute_reply.started":"2025-03-24T13:25:19.653914Z","shell.execute_reply":"2025-03-24T13:25:20.618942Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.25M/6.25M [00:00<00:00, 123MB/s]\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"folder_path = '/kaggle/input/mot16-dataset/MOT16/test/MOT16-07/img1'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:59:52.394012Z","iopub.execute_input":"2025-03-24T13:59:52.394326Z","iopub.status.idle":"2025-03-24T13:59:52.397981Z","shell.execute_reply.started":"2025-03-24T13:59:52.394304Z","shell.execute_reply":"2025-03-24T13:59:52.397231Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"get_feature_file_yolo_detector(yolo, model, folder_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T13:59:57.046509Z","iopub.execute_input":"2025-03-24T13:59:57.046809Z","iopub.status.idle":"2025-03-24T14:01:30.679718Z","shell.execute_reply.started":"2025-03-24T13:59:57.046785Z","shell.execute_reply":"2025-03-24T14:01:30.678864Z"}},"outputs":[{"name":"stdout","text":"\n0: 384x640 12 persons, 1 bus, 2 benchs, 5 handbags, 1 suitcase, 10.0ms\nSpeed: 3.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n1\n\n0: 384x640 13 persons, 2 benchs, 7 handbags, 1 suitcase, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n2\n\n0: 384x640 14 persons, 2 benchs, 5 handbags, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n3\n\n0: 384x640 14 persons, 2 benchs, 6 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n4\n\n0: 384x640 16 persons, 3 benchs, 6 handbags, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n5\n\n0: 384x640 13 persons, 3 benchs, 6 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n6\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n7\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 1 suitcase, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n8\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n9\n\n0: 384x640 14 persons, 2 benchs, 4 handbags, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n10\n\n0: 384x640 14 persons, 2 benchs, 7 handbags, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n11\n\n0: 384x640 13 persons, 2 benchs, 8 handbags, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n12\n\n0: 384x640 14 persons, 2 benchs, 8 handbags, 8.7ms\nSpeed: 2.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n13\n\n0: 384x640 13 persons, 2 benchs, 3 handbags, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n14\n\n0: 384x640 10 persons, 1 car, 2 benchs, 4 handbags, 8.7ms\nSpeed: 2.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n15\n\n0: 384x640 12 persons, 1 car, 2 benchs, 6 handbags, 8.3ms\nSpeed: 3.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n16\n\n0: 384x640 15 persons, 2 benchs, 7 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n17\n\n0: 384x640 13 persons, 2 benchs, 7 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n18\n\n0: 384x640 12 persons, 2 benchs, 8 handbags, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n19\n\n0: 384x640 12 persons, 2 benchs, 7 handbags, 1 suitcase, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n20\n\n0: 384x640 15 persons, 2 benchs, 6 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n21\n\n0: 384x640 11 persons, 1 bench, 9 handbags, 1 suitcase, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n22\n\n0: 384x640 13 persons, 2 benchs, 7 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n23\n\n0: 384x640 11 persons, 1 bench, 8 handbags, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n24\n\n0: 384x640 13 persons, 2 benchs, 7 handbags, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n25\n\n0: 384x640 13 persons, 1 bench, 8 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n26\n\n0: 384x640 13 persons, 1 bench, 6 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n27\n\n0: 384x640 13 persons, 1 bench, 5 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n28\n\n0: 384x640 14 persons, 1 bench, 5 handbags, 1 suitcase, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n29\n\n0: 384x640 13 persons, 1 bench, 3 handbags, 1 suitcase, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n30\n\n0: 384x640 14 persons, 1 bench, 3 handbags, 6.9ms\nSpeed: 2.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n31\n\n0: 384x640 14 persons, 2 benchs, 5 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n32\n\n0: 384x640 14 persons, 2 benchs, 6 handbags, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n33\n\n0: 384x640 13 persons, 1 bench, 5 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n34\n\n0: 384x640 13 persons, 2 benchs, 6 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n35\n\n0: 384x640 14 persons, 2 benchs, 6 handbags, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n36\n\n0: 384x640 13 persons, 2 benchs, 3 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n37\n\n0: 384x640 12 persons, 2 benchs, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n38\n\n0: 384x640 14 persons, 2 benchs, 4 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n39\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n40\n\n0: 384x640 14 persons, 2 benchs, 3 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n41\n\n0: 384x640 15 persons, 2 benchs, 3 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n42\n\n0: 384x640 13 persons, 2 benchs, 4 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n43\n\n0: 384x640 13 persons, 1 bench, 3 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n44\n\n0: 384x640 11 persons, 1 bench, 4 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n45\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n46\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n47\n\n0: 384x640 11 persons, 2 benchs, 3 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n48\n\n0: 384x640 11 persons, 1 bench, 7 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n49\n\n0: 384x640 11 persons, 2 benchs, 9 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n50\n\n0: 384x640 11 persons, 2 benchs, 8 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n51\n\n0: 384x640 10 persons, 2 benchs, 5 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n52\n\n0: 384x640 10 persons, 2 benchs, 8 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n53\n\n0: 384x640 11 persons, 2 benchs, 5 handbags, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n54\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n55\n\n0: 384x640 11 persons, 1 bench, 3 handbags, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n56\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n57\n\n0: 384x640 13 persons, 2 benchs, 5 handbags, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n58\n\n0: 384x640 11 persons, 2 benchs, 1 dog, 5 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n59\n\n0: 384x640 11 persons, 2 benchs, 9 handbags, 7.4ms\nSpeed: 2.4ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n60\n\n0: 384x640 11 persons, 2 benchs, 4 handbags, 1 skateboard, 7.0ms\nSpeed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n61\n\n0: 384x640 10 persons, 1 bench, 5 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n62\n\n0: 384x640 12 persons, 1 bench, 7 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n63\n\n0: 384x640 10 persons, 1 bench, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n64\n\n0: 384x640 14 persons, 1 bench, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n65\n\n0: 384x640 13 persons, 1 bench, 5 handbags, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n66\n\n0: 384x640 14 persons, 1 bench, 6 handbags, 7.0ms\nSpeed: 2.4ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n67\n\n0: 384x640 18 persons, 1 bench, 7 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n68\n\n0: 384x640 13 persons, 1 bench, 7 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n69\n\n0: 384x640 9 persons, 1 bench, 6 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n70\n\n0: 384x640 12 persons, 1 bench, 7 handbags, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n71\n\n0: 384x640 10 persons, 1 bench, 5 handbags, 7.4ms\nSpeed: 2.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n72\n\n0: 384x640 13 persons, 1 bench, 4 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n73\n\n0: 384x640 13 persons, 1 bench, 8 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n74\n\n0: 384x640 11 persons, 1 bench, 12 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n75\n\n0: 384x640 12 persons, 1 bench, 9 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n76\n\n0: 384x640 15 persons, 1 bench, 8 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n77\n\n0: 384x640 15 persons, 1 bench, 9 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n78\n\n0: 384x640 14 persons, 1 bench, 8 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n79\n\n0: 384x640 14 persons, 1 bench, 6 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n80\n\n0: 384x640 12 persons, 1 bench, 8 handbags, 7.6ms\nSpeed: 2.4ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n81\n\n0: 384x640 14 persons, 1 bench, 9 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n82\n\n0: 384x640 14 persons, 1 bench, 8 handbags, 1 suitcase, 2 skateboards, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n83\n\n0: 384x640 16 persons, 1 bench, 7 handbags, 1 suitcase, 2 skateboards, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n84\n\n0: 384x640 14 persons, 1 bench, 7 handbags, 1 suitcase, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n85\n\n0: 384x640 14 persons, 6 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n86\n\n0: 384x640 17 persons, 4 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n87\n\n0: 384x640 13 persons, 5 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n88\n\n0: 384x640 12 persons, 1 bench, 5 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n89\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n90\n\n0: 384x640 11 persons, 4 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n91\n\n0: 384x640 11 persons, 1 bench, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n92\n\n0: 384x640 14 persons, 2 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n93\n\n0: 384x640 13 persons, 3 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n94\n\n0: 384x640 12 persons, 4 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n95\n\n0: 384x640 10 persons, 3 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n96\n\n0: 384x640 12 persons, 6 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n97\n\n0: 384x640 11 persons, 4 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n98\n\n0: 384x640 13 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n99\n\n0: 384x640 11 persons, 5 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n100\n\n0: 384x640 11 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n101\n\n0: 384x640 11 persons, 4 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n102\n\n0: 384x640 9 persons, 4 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n103\n\n0: 384x640 9 persons, 4 handbags, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n104\n\n0: 384x640 9 persons, 4 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n105\n\n0: 384x640 7 persons, 3 handbags, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n106\n\n0: 384x640 7 persons, 1 handbag, 7.9ms\nSpeed: 2.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n107\n\n0: 384x640 10 persons, 2 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n108\n\n0: 384x640 11 persons, 3 handbags, 6.5ms\nSpeed: 2.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n109\n\n0: 384x640 7 persons, 1 car, 1 bench, 3 handbags, 7.4ms\nSpeed: 2.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n110\n\n0: 384x640 8 persons, 1 bench, 3 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n111\n\n0: 384x640 11 persons, 1 bench, 2 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n112\n\n0: 384x640 13 persons, 1 bicycle, 3 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n113\n\n0: 384x640 13 persons, 2 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n114\n\n0: 384x640 12 persons, 3 handbags, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n115\n\n0: 384x640 10 persons, 1 bench, 4 handbags, 1 clock, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n116\n\n0: 384x640 10 persons, 4 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n117\n\n0: 384x640 11 persons, 4 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n118\n\n0: 384x640 10 persons, 3 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n119\n\n0: 384x640 9 persons, 4 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n120\n\n0: 384x640 10 persons, 3 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n121\n\n0: 384x640 12 persons, 4 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n122\n\n0: 384x640 11 persons, 4 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n123\n\n0: 384x640 11 persons, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n124\n\n0: 384x640 11 persons, 3 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n125\n\n0: 384x640 11 persons, 3 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n126\n\n0: 384x640 12 persons, 5 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n127\n\n0: 384x640 15 persons, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n128\n\n0: 384x640 13 persons, 7 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n129\n\n0: 384x640 15 persons, 8 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n130\n\n0: 384x640 13 persons, 6 handbags, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n131\n\n0: 384x640 12 persons, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n132\n\n0: 384x640 14 persons, 6 handbags, 1 suitcase, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n133\n\n0: 384x640 13 persons, 7 handbags, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n134\n\n0: 384x640 15 persons, 7 handbags, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n135\n\n0: 384x640 15 persons, 7 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n136\n\n0: 384x640 17 persons, 4 handbags, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n137\n\n0: 384x640 14 persons, 4 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n138\n\n0: 384x640 17 persons, 7 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n139\n\n0: 384x640 15 persons, 5 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n140\n\n0: 384x640 14 persons, 3 handbags, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n141\n\n0: 384x640 16 persons, 3 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n142\n\n0: 384x640 14 persons, 3 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n143\n\n0: 384x640 15 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n144\n\n0: 384x640 15 persons, 5 handbags, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n145\n\n0: 384x640 16 persons, 7 handbags, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n146\n\n0: 384x640 18 persons, 7 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n147\n\n0: 384x640 15 persons, 7 handbags, 1 suitcase, 6.7ms\nSpeed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n148\n\n0: 384x640 13 persons, 9 handbags, 6.9ms\nSpeed: 2.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n149\n\n0: 384x640 14 persons, 9 handbags, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n150\n\n0: 384x640 13 persons, 8 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n151\n\n0: 384x640 12 persons, 9 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n152\n\n0: 384x640 12 persons, 9 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n153\n\n0: 384x640 13 persons, 8 handbags, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n154\n\n0: 384x640 13 persons, 7 handbags, 8.3ms\nSpeed: 2.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n155\n\n0: 384x640 15 persons, 8 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n156\n\n0: 384x640 13 persons, 7 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n157\n\n0: 384x640 14 persons, 4 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n158\n\n0: 384x640 16 persons, 4 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n159\n\n0: 384x640 15 persons, 4 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n160\n\n0: 384x640 18 persons, 5 handbags, 1 suitcase, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n161\n\n0: 384x640 17 persons, 1 backpack, 5 handbags, 1 suitcase, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n162\n\n0: 384x640 15 persons, 7 handbags, 1 clock, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n163\n\n0: 384x640 17 persons, 4 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n164\n\n0: 384x640 18 persons, 4 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n165\n\n0: 384x640 16 persons, 6 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n166\n\n0: 384x640 16 persons, 6 handbags, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n167\n\n0: 384x640 16 persons, 4 handbags, 1 clock, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n168\n\n0: 384x640 11 persons, 4 handbags, 1 clock, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n169\n\n0: 384x640 14 persons, 4 handbags, 1 clock, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n170\n\n0: 384x640 12 persons, 5 handbags, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n171\n\n0: 384x640 15 persons, 5 handbags, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n172\n\n0: 384x640 14 persons, 5 handbags, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n173\n\n0: 384x640 11 persons, 5 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n174\n\n0: 384x640 16 persons, 3 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n175\n\n0: 384x640 18 persons, 2 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n176\n\n0: 384x640 16 persons, 3 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n177\n\n0: 384x640 16 persons, 1 dog, 5 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n178\n\n0: 384x640 20 persons, 1 backpack, 2 handbags, 1 clock, 8.7ms\nSpeed: 3.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n179\n\n0: 384x640 19 persons, 4 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n180\n\n0: 384x640 21 persons, 1 backpack, 4 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n181\n\n0: 384x640 20 persons, 1 backpack, 3 handbags, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n182\n\n0: 384x640 19 persons, 1 bench, 2 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n183\n\n0: 384x640 17 persons, 1 bench, 1 backpack, 2 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n184\n\n0: 384x640 20 persons, 4 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n185\n\n0: 384x640 17 persons, 1 bench, 1 backpack, 3 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n186\n\n0: 384x640 15 persons, 1 bench, 1 backpack, 3 handbags, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n187\n\n0: 384x640 20 persons, 6 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n188\n\n0: 384x640 18 persons, 1 backpack, 5 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n189\n\n0: 384x640 16 persons, 7 handbags, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n190\n\n0: 384x640 19 persons, 2 traffic lights, 4 handbags, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n191\n\n0: 384x640 20 persons, 4 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n192\n\n0: 384x640 21 persons, 2 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n193\n\n0: 384x640 17 persons, 1 handbag, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n194\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n195\n\n0: 384x640 16 persons, 2 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n196\n\n0: 384x640 17 persons, 1 bench, 3 handbags, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n197\n\n0: 384x640 17 persons, 3 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n198\n\n0: 384x640 15 persons, 1 backpack, 3 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n199\n\n0: 384x640 13 persons, 3 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n200\n\n0: 384x640 16 persons, 1 dog, 3 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n201\n\n0: 384x640 19 persons, 2 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n202\n\n0: 384x640 16 persons, 3 handbags, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n203\n\n0: 384x640 18 persons, 3 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n204\n\n0: 384x640 19 persons, 3 handbags, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n205\n\n0: 384x640 18 persons, 3 handbags, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n206\n\n0: 384x640 19 persons, 1 handbag, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n207\n\n0: 384x640 18 persons, 2 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n208\n\n0: 384x640 19 persons, 2 handbags, 1 suitcase, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n209\n\n0: 384x640 16 persons, 3 handbags, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n210\n\n0: 384x640 17 persons, 1 motorcycle, 4 handbags, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n211\n\n0: 384x640 18 persons, 1 motorcycle, 4 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n212\n\n0: 384x640 18 persons, 3 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n213\n\n0: 384x640 19 persons, 4 handbags, 1 suitcase, 6.7ms\nSpeed: 2.0ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n214\n\n0: 384x640 16 persons, 5 handbags, 7.0ms\nSpeed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n215\n\n0: 384x640 17 persons, 4 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n216\n\n0: 384x640 15 persons, 2 handbags, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n217\n\n0: 384x640 12 persons, 3 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n218\n\n0: 384x640 11 persons, 2 handbags, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n219\n\n0: 384x640 9 persons, 2 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n220\n\n0: 384x640 13 persons, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n221\n\n0: 384x640 13 persons, 3 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n222\n\n0: 384x640 13 persons, 3 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n223\n\n0: 384x640 14 persons, 3 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n224\n\n0: 384x640 13 persons, 4 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n225\n\n0: 384x640 16 persons, 4 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n226\n\n0: 384x640 16 persons, 1 backpack, 5 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n227\n\n0: 384x640 16 persons, 4 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n228\n\n0: 384x640 16 persons, 5 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n229\n\n0: 384x640 17 persons, 1 backpack, 3 handbags, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n230\n\n0: 384x640 16 persons, 1 backpack, 3 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n231\n\n0: 384x640 17 persons, 4 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n232\n\n0: 384x640 17 persons, 1 backpack, 5 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n233\n\n0: 384x640 17 persons, 1 backpack, 6 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n234\n\n0: 384x640 16 persons, 6 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n235\n\n0: 384x640 14 persons, 6 handbags, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n236\n\n0: 384x640 15 persons, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n237\n\n0: 384x640 15 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n238\n\n0: 384x640 17 persons, 5 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n239\n\n0: 384x640 15 persons, 2 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n240\n\n0: 384x640 14 persons, 4 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n241\n\n0: 384x640 14 persons, 7 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n242\n\n0: 384x640 18 persons, 8 handbags, 1 suitcase, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n243\n\n0: 384x640 16 persons, 4 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n244\n\n0: 384x640 14 persons, 5 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n245\n\n0: 384x640 15 persons, 6 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n246\n\n0: 384x640 14 persons, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n247\n\n0: 384x640 13 persons, 5 handbags, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n248\n\n0: 384x640 10 persons, 5 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n249\n\n0: 384x640 16 persons, 3 handbags, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n250\n\n0: 384x640 12 persons, 4 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n251\n\n0: 384x640 11 persons, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n252\n\n0: 384x640 14 persons, 7 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n253\n\n0: 384x640 12 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n254\n\n0: 384x640 12 persons, 5 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n255\n\n0: 384x640 12 persons, 1 car, 4 handbags, 7.8ms\nSpeed: 2.2ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n256\n\n0: 384x640 10 persons, 1 car, 4 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n257\n\n0: 384x640 13 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n258\n\n0: 384x640 15 persons, 8 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n259\n\n0: 384x640 12 persons, 7 handbags, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n260\n\n0: 384x640 13 persons, 5 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n261\n\n0: 384x640 10 persons, 5 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n262\n\n0: 384x640 11 persons, 7 handbags, 1 suitcase, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n263\n\n0: 384x640 12 persons, 5 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n264\n\n0: 384x640 8 persons, 4 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n265\n\n0: 384x640 10 persons, 4 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n266\n\n0: 384x640 12 persons, 7 handbags, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n267\n\n0: 384x640 12 persons, 6 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n268\n\n0: 384x640 11 persons, 6 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n269\n\n0: 384x640 11 persons, 7 handbags, 1 suitcase, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n270\n\n0: 384x640 11 persons, 3 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n271\n\n0: 384x640 13 persons, 6 handbags, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n272\n\n0: 384x640 8 persons, 5 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n273\n\n0: 384x640 10 persons, 5 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n274\n\n0: 384x640 9 persons, 3 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n275\n\n0: 384x640 11 persons, 3 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n276\n\n0: 384x640 13 persons, 3 handbags, 1 suitcase, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n277\n\n0: 384x640 14 persons, 5 handbags, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n278\n\n0: 384x640 13 persons, 6 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n279\n\n0: 384x640 11 persons, 7 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n280\n\n0: 384x640 11 persons, 6 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n281\n\n0: 384x640 12 persons, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n282\n\n0: 384x640 13 persons, 6 handbags, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n283\n\n0: 384x640 12 persons, 3 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n284\n\n0: 384x640 11 persons, 4 handbags, 7.7ms\nSpeed: 2.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n285\n\n0: 384x640 17 persons, 2 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n286\n\n0: 384x640 12 persons, 5 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n287\n\n0: 384x640 13 persons, 3 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n288\n\n0: 384x640 12 persons, 4 handbags, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n289\n\n0: 384x640 13 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n290\n\n0: 384x640 12 persons, 3 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n291\n\n0: 384x640 10 persons, 3 handbags, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n292\n\n0: 384x640 9 persons, 3 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n293\n\n0: 384x640 9 persons, 4 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n294\n\n0: 384x640 9 persons, 5 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n295\n\n0: 384x640 10 persons, 4 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n296\n\n0: 384x640 11 persons, 2 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n297\n\n0: 384x640 12 persons, 2 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n298\n\n0: 384x640 11 persons, 2 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n299\n\n0: 384x640 13 persons, 1 handbag, 6.7ms\nSpeed: 2.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n300\n\n0: 384x640 12 persons, 2 handbags, 6.5ms\nSpeed: 2.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n301\n\n0: 384x640 14 persons, 3 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n302\n\n0: 384x640 15 persons, 4 handbags, 6.6ms\nSpeed: 2.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n303\n\n0: 384x640 17 persons, 1 bus, 4 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n304\n\n0: 384x640 16 persons, 3 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n305\n\n0: 384x640 15 persons, 3 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n306\n\n0: 384x640 16 persons, 4 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n307\n\n0: 384x640 20 persons, 4 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n308\n\n0: 384x640 15 persons, 2 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n309\n\n0: 384x640 16 persons, 3 handbags, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n310\n\n0: 384x640 16 persons, 3 handbags, 7.8ms\nSpeed: 2.4ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n311\n\n0: 384x640 17 persons, 3 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n312\n\n0: 384x640 17 persons, 4 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n313\n\n0: 384x640 14 persons, 4 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n314\n\n0: 384x640 13 persons, 5 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n315\n\n0: 384x640 13 persons, 4 handbags, 7.2ms\nSpeed: 2.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n316\n\n0: 384x640 13 persons, 4 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n317\n\n0: 384x640 18 persons, 5 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n318\n\n0: 384x640 19 persons, 3 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n319\n\n0: 384x640 25 persons, 2 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n320\n\n0: 384x640 21 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n321\n\n0: 384x640 22 persons, 1 handbag, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n322\n\n0: 384x640 22 persons, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n323\n\n0: 384x640 17 persons, 2 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n324\n\n0: 384x640 19 persons, 2 handbags, 7.5ms\nSpeed: 2.4ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n325\n\n0: 384x640 20 persons, 1 car, 3 handbags, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n326\n\n0: 384x640 19 persons, 2 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n327\n\n0: 384x640 19 persons, 1 car, 1 handbag, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n328\n\n0: 384x640 16 persons, 2 handbags, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n329\n\n0: 384x640 19 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n330\n\n0: 384x640 15 persons, 1 car, 3 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n331\n\n0: 384x640 18 persons, 3 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n332\n\n0: 384x640 17 persons, 3 handbags, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n333\n\n0: 384x640 14 persons, 1 handbag, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n334\n\n0: 384x640 18 persons, 2 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n335\n\n0: 384x640 15 persons, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n336\n\n0: 384x640 14 persons, 2 handbags, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n337\n\n0: 384x640 19 persons, 1 car, 1 handbag, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n338\n\n0: 384x640 12 persons, 1 car, 1 handbag, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n339\n\n0: 384x640 16 persons, 1 car, 1 handbag, 7.8ms\nSpeed: 2.6ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n340\n\n0: 384x640 16 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n341\n\n0: 384x640 15 persons, 1 handbag, 7.3ms\nSpeed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n342\n\n0: 384x640 16 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n343\n\n0: 384x640 18 persons, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n344\n\n0: 384x640 15 persons, 7.2ms\nSpeed: 2.4ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n345\n\n0: 384x640 16 persons, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n346\n\n0: 384x640 17 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n347\n\n0: 384x640 16 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n348\n\n0: 384x640 17 persons, 1 handbag, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n349\n\n0: 384x640 16 persons, 1 handbag, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n350\n\n0: 384x640 16 persons, 1 handbag, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n351\n\n0: 384x640 15 persons, 1 handbag, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n352\n\n0: 384x640 17 persons, 1 handbag, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n353\n\n0: 384x640 18 persons, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n354\n\n0: 384x640 17 persons, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n355\n\n0: 384x640 18 persons, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n356\n\n0: 384x640 16 persons, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n357\n\n0: 384x640 18 persons, 1 handbag, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n358\n\n0: 384x640 20 persons, 1 handbag, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n359\n\n0: 384x640 21 persons, 1 handbag, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n360\n\n0: 384x640 22 persons, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n361\n\n0: 384x640 19 persons, 1 handbag, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n362\n\n0: 384x640 21 persons, 1 handbag, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n363\n\n0: 384x640 18 persons, 1 handbag, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n364\n\n0: 384x640 16 persons, 1 handbag, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n365\n\n0: 384x640 16 persons, 1 handbag, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n366\n\n0: 384x640 16 persons, 1 handbag, 7.8ms\nSpeed: 2.4ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n367\n\n0: 384x640 17 persons, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n368\n\n0: 384x640 17 persons, 1 handbag, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n369\n\n0: 384x640 18 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n370\n\n0: 384x640 21 persons, 10.6ms\nSpeed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n371\n\n0: 384x640 17 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n372\n\n0: 384x640 17 persons, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n373\n\n0: 384x640 16 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n374\n\n0: 384x640 18 persons, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n375\n\n0: 384x640 17 persons, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n376\n\n0: 384x640 18 persons, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n377\n\n0: 384x640 17 persons, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n378\n\n0: 384x640 16 persons, 1 handbag, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n379\n\n0: 384x640 17 persons, 1 handbag, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n380\n\n0: 384x640 17 persons, 2 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n381\n\n0: 384x640 15 persons, 1 handbag, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n382\n\n0: 384x640 18 persons, 1 handbag, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n383\n\n0: 384x640 18 persons, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n384\n\n0: 384x640 18 persons, 2 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n385\n\n0: 384x640 18 persons, 2 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n386\n\n0: 384x640 17 persons, 1 handbag, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n387\n\n0: 384x640 19 persons, 1 handbag, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n388\n\n0: 384x640 17 persons, 1 handbag, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n389\n\n0: 384x640 18 persons, 1 car, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n390\n\n0: 384x640 19 persons, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n391\n\n0: 384x640 18 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n392\n\n0: 384x640 17 persons, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n393\n\n0: 384x640 17 persons, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n394\n\n0: 384x640 15 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n395\n\n0: 384x640 19 persons, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n396\n\n0: 384x640 16 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n397\n\n0: 384x640 15 persons, 1 handbag, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n398\n\n0: 384x640 13 persons, 7.9ms\nSpeed: 2.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n399\n\n0: 384x640 16 persons, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n400\n\n0: 384x640 15 persons, 7.9ms\nSpeed: 2.7ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n401\n\n0: 384x640 16 persons, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n402\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n403\n\n0: 384x640 17 persons, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n404\n\n0: 384x640 15 persons, 1 skateboard, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n405\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n406\n\n0: 384x640 13 persons, 1 handbag, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n407\n\n0: 384x640 11 persons, 1 handbag, 6.5ms\nSpeed: 2.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n408\n\n0: 384x640 12 persons, 1 handbag, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n409\n\n0: 384x640 12 persons, 1 handbag, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n410\n\n0: 384x640 12 persons, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n411\n\n0: 384x640 12 persons, 2 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n412\n\n0: 384x640 14 persons, 2 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n413\n\n0: 384x640 14 persons, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n414\n\n0: 384x640 17 persons, 2 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n415\n\n0: 384x640 12 persons, 1 handbag, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n416\n\n0: 384x640 16 persons, 1 handbag, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n417\n\n0: 384x640 18 persons, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n418\n\n0: 384x640 17 persons, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n419\n\n0: 384x640 16 persons, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n420\n\n0: 384x640 13 persons, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n421\n\n0: 384x640 13 persons, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n422\n\n0: 384x640 18 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n423\n\n0: 384x640 17 persons, 1 skateboard, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n424\n\n0: 384x640 17 persons, 1 suitcase, 1 skateboard, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n425\n\n0: 384x640 16 persons, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n426\n\n0: 384x640 14 persons, 8.3ms\nSpeed: 2.2ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n427\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n428\n\n0: 384x640 13 persons, 1 suitcase, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n429\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n430\n\n0: 384x640 19 persons, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n431\n\n0: 384x640 16 persons, 1 suitcase, 7.5ms\nSpeed: 2.4ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n432\n\n0: 384x640 13 persons, 1 handbag, 1 suitcase, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n433\n\n0: 384x640 13 persons, 1 suitcase, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n434\n\n0: 384x640 16 persons, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n435\n\n0: 384x640 17 persons, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n436\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n437\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n438\n\n0: 384x640 11 persons, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n439\n\n0: 384x640 12 persons, 1 handbag, 2 suitcases, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n440\n\n0: 384x640 12 persons, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n441\n\n0: 384x640 12 persons, 1 suitcase, 6.6ms\nSpeed: 2.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n442\n\n0: 384x640 14 persons, 1 suitcase, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n443\n\n0: 384x640 14 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n444\n\n0: 384x640 11 persons, 1 suitcase, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n445\n\n0: 384x640 14 persons, 1 suitcase, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n446\n\n0: 384x640 13 persons, 1 suitcase, 7.3ms\nSpeed: 2.4ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n447\n\n0: 384x640 13 persons, 1 suitcase, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n448\n\n0: 384x640 14 persons, 1 suitcase, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n449\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n450\n\n0: 384x640 16 persons, 1 suitcase, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n451\n\n0: 384x640 16 persons, 1 handbag, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n452\n\n0: 384x640 15 persons, 2 suitcases, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n453\n\n0: 384x640 16 persons, 1 handbag, 1 suitcase, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n454\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n455\n\n0: 384x640 13 persons, 1 suitcase, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n456\n\n0: 384x640 13 persons, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n457\n\n0: 384x640 14 persons, 1 suitcase, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n458\n\n0: 384x640 15 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n459\n\n0: 384x640 17 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n460\n\n0: 384x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n461\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n462\n\n0: 384x640 14 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n463\n\n0: 384x640 14 persons, 1 suitcase, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n464\n\n0: 384x640 11 persons, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n465\n\n0: 384x640 11 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n466\n\n0: 384x640 11 persons, 1 suitcase, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n467\n\n0: 384x640 13 persons, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n468\n\n0: 384x640 17 persons, 6.7ms\nSpeed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n469\n\n0: 384x640 14 persons, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n470\n\n0: 384x640 14 persons, 1 suitcase, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n471\n\n0: 384x640 15 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n472\n\n0: 384x640 14 persons, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n473\n\n0: 384x640 16 persons, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n474\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n475\n\n0: 384x640 15 persons, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n476\n\n0: 384x640 16 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n477\n\n0: 384x640 12 persons, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n478\n\n0: 384x640 12 persons, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n479\n\n0: 384x640 11 persons, 1 suitcase, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n480\n\n0: 384x640 13 persons, 1 suitcase, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n481\n\n0: 384x640 13 persons, 1 suitcase, 9.2ms\nSpeed: 2.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n482\n\n0: 384x640 15 persons, 2 suitcases, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n483\n\n0: 384x640 12 persons, 2 suitcases, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n484\n\n0: 384x640 14 persons, 2 suitcases, 6.5ms\nSpeed: 2.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n485\n\n0: 384x640 15 persons, 2 suitcases, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n486\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n487\n\n0: 384x640 11 persons, 1 suitcase, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n488\n\n0: 384x640 13 persons, 1 suitcase, 7.5ms\nSpeed: 2.3ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n489\n\n0: 384x640 16 persons, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n490\n\n0: 384x640 14 persons, 1 suitcase, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n491\n\n0: 384x640 16 persons, 2 suitcases, 10.0ms\nSpeed: 2.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n492\n\n0: 384x640 16 persons, 1 backpack, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n493\n\n0: 384x640 14 persons, 1 suitcase, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n494\n\n0: 384x640 18 persons, 1 suitcase, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n495\n\n0: 384x640 17 persons, 2 suitcases, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n496\n\n0: 384x640 18 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n497\n\n0: 384x640 17 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n498\n\n0: 384x640 14 persons, 1 suitcase, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n499\n\n0: 384x640 16 persons, 1 suitcase, 6.7ms\nSpeed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n500\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"video_path = '/kaggle/input/mot16-07/MOT16-07-raw.webm'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T14:05:20.098332Z","iopub.execute_input":"2025-03-24T14:05:20.098613Z","iopub.status.idle":"2025-03-24T14:05:20.102319Z","shell.execute_reply.started":"2025-03-24T14:05:20.098593Z","shell.execute_reply":"2025-03-24T14:05:20.101574Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"get_feature_file_from_video(yolo, model, video_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T14:05:21.883714Z","iopub.execute_input":"2025-03-24T14:05:21.884074Z","iopub.status.idle":"2025-03-24T14:06:44.892871Z","shell.execute_reply.started":"2025-03-24T14:05:21.884046Z","shell.execute_reply":"2025-03-24T14:06:44.891935Z"}},"outputs":[{"name":"stdout","text":"\n0: 384x640 15 persons, 2 benchs, 6 handbags, 8.4ms\nSpeed: 2.3ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n1\n\n0: 384x640 12 persons, 2 benchs, 4 handbags, 7.4ms\nSpeed: 3.3ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n2\n\n0: 384x640 11 persons, 2 benchs, 4 handbags, 6.6ms\nSpeed: 3.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n3\n\n0: 384x640 16 persons, 2 benchs, 5 handbags, 7.5ms\nSpeed: 2.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n4\n\n0: 384x640 15 persons, 2 benchs, 6 handbags, 7.3ms\nSpeed: 2.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n5\n\n0: 384x640 14 persons, 2 benchs, 6 handbags, 8.8ms\nSpeed: 2.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n6\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n7\n\n0: 384x640 14 persons, 2 benchs, 4 handbags, 1 suitcase, 7.7ms\nSpeed: 2.4ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n8\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 1 suitcase, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n9\n\n0: 384x640 13 persons, 2 benchs, 3 handbags, 1 suitcase, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n10\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 6.9ms\nSpeed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n11\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 7.7ms\nSpeed: 2.7ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n12\n\n0: 384x640 14 persons, 2 benchs, 1 backpack, 4 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n13\n\n0: 384x640 12 persons, 2 benchs, 4 handbags, 1 suitcase, 9.1ms\nSpeed: 2.5ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n14\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 7.1ms\nSpeed: 2.6ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n15\n\n0: 384x640 10 persons, 2 benchs, 5 handbags, 7.4ms\nSpeed: 2.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n16\n\n0: 384x640 11 persons, 2 benchs, 5 handbags, 7.3ms\nSpeed: 2.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n17\n\n0: 384x640 12 persons, 2 benchs, 4 handbags, 8.7ms\nSpeed: 2.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n18\n\n0: 384x640 13 persons, 2 benchs, 4 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n19\n\n0: 384x640 13 persons, 2 benchs, 4 handbags, 1 suitcase, 7.6ms\nSpeed: 2.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n20\n\n0: 384x640 15 persons, 3 benchs, 4 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n21\n\n0: 384x640 13 persons, 2 benchs, 3 handbags, 8.7ms\nSpeed: 2.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n22\n\n0: 384x640 12 persons, 2 benchs, 8 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n23\n\n0: 384x640 12 persons, 2 benchs, 7 handbags, 7.6ms\nSpeed: 2.7ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n24\n\n0: 384x640 11 persons, 2 benchs, 5 handbags, 1 suitcase, 7.7ms\nSpeed: 2.6ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n25\n\n0: 384x640 10 persons, 1 bench, 2 handbags, 7.9ms\nSpeed: 2.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n26\n\n0: 384x640 11 persons, 1 bench, 3 handbags, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n27\n\n0: 384x640 11 persons, 1 bench, 2 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n28\n\n0: 384x640 12 persons, 2 benchs, 3 handbags, 6.9ms\nSpeed: 2.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n29\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n30\n\n0: 384x640 13 persons, 1 bench, 3 handbags, 1 suitcase, 7.5ms\nSpeed: 2.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n31\n\n0: 384x640 12 persons, 1 bench, 2 handbags, 8.0ms\nSpeed: 2.9ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n32\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 1 suitcase, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n33\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 8.2ms\nSpeed: 2.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n34\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n35\n\n0: 384x640 11 persons, 1 bench, 4 handbags, 1 suitcase, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n36\n\n0: 384x640 11 persons, 1 bench, 4 handbags, 1 suitcase, 7.3ms\nSpeed: 2.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n37\n\n0: 384x640 11 persons, 1 bench, 3 handbags, 9.1ms\nSpeed: 2.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n38\n\n0: 384x640 12 persons, 2 benchs, 2 handbags, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n39\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 7.5ms\nSpeed: 2.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n40\n\n0: 384x640 13 persons, 1 bench, 3 handbags, 7.5ms\nSpeed: 2.6ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n41\n\n0: 384x640 13 persons, 1 bench, 3 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n42\n\n0: 384x640 12 persons, 2 benchs, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n43\n\n0: 384x640 12 persons, 1 bench, 3 handbags, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n44\n\n0: 384x640 10 persons, 2 benchs, 3 handbags, 11.0ms\nSpeed: 3.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n45\n\n0: 384x640 13 persons, 2 benchs, 2 handbags, 9.0ms\nSpeed: 2.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n46\n\n0: 384x640 14 persons, 2 benchs, 4 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n47\n\n0: 384x640 13 persons, 2 benchs, 4 handbags, 8.8ms\nSpeed: 2.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n48\n\n0: 384x640 13 persons, 2 benchs, 5 handbags, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n49\n\n0: 384x640 12 persons, 2 benchs, 4 handbags, 8.1ms\nSpeed: 2.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n50\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n51\n\n0: 384x640 11 persons, 2 benchs, 5 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n52\n\n0: 384x640 11 persons, 1 bench, 4 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n53\n\n0: 384x640 11 persons, 2 benchs, 2 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n54\n\n0: 384x640 11 persons, 2 benchs, 2 handbags, 7.3ms\nSpeed: 2.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n55\n\n0: 384x640 10 persons, 2 benchs, 2 handbags, 7.9ms\nSpeed: 2.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n56\n\n0: 384x640 15 persons, 2 benchs, 5 handbags, 8.0ms\nSpeed: 2.5ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n57\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 8.9ms\nSpeed: 2.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n58\n\n0: 384x640 12 persons, 2 benchs, 6 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n59\n\n0: 384x640 13 persons, 2 benchs, 7 handbags, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n60\n\n0: 384x640 16 persons, 2 benchs, 4 handbags, 1 skateboard, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n61\n\n0: 384x640 14 persons, 2 benchs, 4 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n62\n\n0: 384x640 13 persons, 2 benchs, 3 handbags, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n63\n\n0: 384x640 12 persons, 2 benchs, 5 handbags, 8.0ms\nSpeed: 2.5ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n64\n\n0: 384x640 13 persons, 2 benchs, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n65\n\n0: 384x640 11 persons, 1 bench, 4 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n66\n\n0: 384x640 11 persons, 1 bench, 2 handbags, 6.4ms\nSpeed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n67\n\n0: 384x640 15 persons, 1 bench, 4 handbags, 9.0ms\nSpeed: 2.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n68\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n69\n\n0: 384x640 12 persons, 1 bench, 2 handbags, 9.0ms\nSpeed: 2.6ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n70\n\n0: 384x640 13 persons, 1 bench, 5 handbags, 8.2ms\nSpeed: 2.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n71\n\n0: 384x640 13 persons, 1 bench, 6 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n72\n\n0: 384x640 12 persons, 1 bench, 1 backpack, 4 handbags, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n73\n\n0: 384x640 13 persons, 1 bench, 1 backpack, 3 handbags, 8.0ms\nSpeed: 2.8ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n74\n\n0: 384x640 10 persons, 1 bench, 1 backpack, 3 handbags, 7.2ms\nSpeed: 2.8ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n75\n\n0: 384x640 12 persons, 1 bench, 1 backpack, 8 handbags, 7.5ms\nSpeed: 2.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n76\n\n0: 384x640 12 persons, 1 bench, 10 handbags, 7.2ms\nSpeed: 2.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n77\n\n0: 384x640 13 persons, 1 bench, 6 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n78\n\n0: 384x640 15 persons, 1 bench, 6 handbags, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n79\n\n0: 384x640 13 persons, 5 handbags, 7.5ms\nSpeed: 2.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n80\n\n0: 384x640 13 persons, 1 bench, 5 handbags, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n81\n\n0: 384x640 16 persons, 1 bench, 5 handbags, 8.6ms\nSpeed: 2.5ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n82\n\n0: 384x640 14 persons, 1 bench, 5 handbags, 1 skateboard, 7.1ms\nSpeed: 2.6ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n83\n\n0: 384x640 13 persons, 1 bench, 1 backpack, 5 handbags, 2 skateboards, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n84\n\n0: 384x640 11 persons, 4 handbags, 7.3ms\nSpeed: 3.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n85\n\n0: 384x640 15 persons, 5 handbags, 9.5ms\nSpeed: 2.8ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n86\n\n0: 384x640 13 persons, 3 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n87\n\n0: 384x640 15 persons, 4 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n88\n\n0: 384x640 13 persons, 4 handbags, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n89\n\n0: 384x640 14 persons, 5 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n90\n\n0: 384x640 12 persons, 5 handbags, 7.0ms\nSpeed: 2.4ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n91\n\n0: 384x640 11 persons, 2 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n92\n\n0: 384x640 15 persons, 2 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n93\n\n0: 384x640 15 persons, 3 handbags, 8.7ms\nSpeed: 2.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n94\n\n0: 384x640 18 persons, 2 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n95\n\n0: 384x640 14 persons, 3 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n96\n\n0: 384x640 15 persons, 2 handbags, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n97\n\n0: 384x640 12 persons, 3 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n98\n\n0: 384x640 12 persons, 5 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n99\n\n0: 384x640 13 persons, 3 handbags, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n100\n\n0: 384x640 13 persons, 6 handbags, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n101\n\n0: 384x640 11 persons, 1 backpack, 6 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n102\n\n0: 384x640 11 persons, 5 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n103\n\n0: 384x640 11 persons, 3 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n104\n\n0: 384x640 9 persons, 6 handbags, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n105\n\n0: 384x640 8 persons, 6 handbags, 8.5ms\nSpeed: 2.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n106\n\n0: 384x640 10 persons, 4 handbags, 9.5ms\nSpeed: 3.5ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n107\n\n0: 384x640 12 persons, 2 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n108\n\n0: 384x640 11 persons, 2 handbags, 7.3ms\nSpeed: 2.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n109\n\n0: 384x640 11 persons, 4 handbags, 8.6ms\nSpeed: 2.5ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n110\n\n0: 384x640 9 persons, 1 bicycle, 4 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n111\n\n0: 384x640 11 persons, 1 bicycle, 2 handbags, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n112\n\n0: 384x640 12 persons, 1 bicycle, 2 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n113\n\n0: 384x640 12 persons, 1 bicycle, 2 handbags, 8.1ms\nSpeed: 2.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n114\n\n0: 384x640 13 persons, 1 bicycle, 3 handbags, 6.9ms\nSpeed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n115\n\n0: 384x640 13 persons, 4 handbags, 6.5ms\nSpeed: 2.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n116\n\n0: 384x640 14 persons, 3 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n117\n\n0: 384x640 13 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n118\n\n0: 384x640 12 persons, 4 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n119\n\n0: 384x640 9 persons, 4 handbags, 7.5ms\nSpeed: 2.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n120\n\n0: 384x640 12 persons, 1 bench, 4 handbags, 7.3ms\nSpeed: 2.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n121\n\n0: 384x640 13 persons, 4 handbags, 7.9ms\nSpeed: 2.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n122\n\n0: 384x640 14 persons, 5 handbags, 7.6ms\nSpeed: 2.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n123\n\n0: 384x640 15 persons, 5 handbags, 7.5ms\nSpeed: 2.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n124\n\n0: 384x640 16 persons, 6 handbags, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n125\n\n0: 384x640 14 persons, 4 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n126\n\n0: 384x640 15 persons, 3 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n127\n\n0: 384x640 15 persons, 4 handbags, 1 tv, 1 clock, 7.4ms\nSpeed: 2.3ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n128\n\n0: 384x640 16 persons, 5 handbags, 7.2ms\nSpeed: 2.8ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n129\n\n0: 384x640 16 persons, 5 handbags, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n130\n\n0: 384x640 15 persons, 4 handbags, 1 clock, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n131\n\n0: 384x640 14 persons, 5 handbags, 1 clock, 7.7ms\nSpeed: 2.6ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n132\n\n0: 384x640 18 persons, 6 handbags, 7.4ms\nSpeed: 2.9ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n133\n\n0: 384x640 14 persons, 7 handbags, 1 clock, 9.0ms\nSpeed: 2.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n134\n\n0: 384x640 14 persons, 7 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n135\n\n0: 384x640 13 persons, 4 handbags, 8.6ms\nSpeed: 2.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n136\n\n0: 384x640 18 persons, 4 handbags, 6.8ms\nSpeed: 2.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n137\n\n0: 384x640 17 persons, 8 handbags, 7.8ms\nSpeed: 2.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n138\n\n0: 384x640 16 persons, 6 handbags, 1 clock, 6.9ms\nSpeed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n139\n\n0: 384x640 16 persons, 5 handbags, 1 clock, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n140\n\n0: 384x640 14 persons, 4 handbags, 6.6ms\nSpeed: 2.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n141\n\n0: 384x640 16 persons, 3 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n142\n\n0: 384x640 17 persons, 2 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n143\n\n0: 384x640 15 persons, 2 handbags, 1 suitcase, 7.3ms\nSpeed: 2.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n144\n\n0: 384x640 17 persons, 3 handbags, 1 suitcase, 1 clock, 9.5ms\nSpeed: 2.6ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n145\n\n0: 384x640 18 persons, 5 handbags, 9.0ms\nSpeed: 2.5ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n146\n\n0: 384x640 17 persons, 3 handbags, 6.9ms\nSpeed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n147\n\n0: 384x640 17 persons, 3 handbags, 1 suitcase, 7.4ms\nSpeed: 2.7ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n148\n\n0: 384x640 15 persons, 8 handbags, 7.2ms\nSpeed: 2.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n149\n\n0: 384x640 14 persons, 8 handbags, 9.0ms\nSpeed: 3.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n150\n\n0: 384x640 15 persons, 6 handbags, 2 suitcases, 9.2ms\nSpeed: 2.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n151\n\n0: 384x640 15 persons, 5 handbags, 1 suitcase, 8.5ms\nSpeed: 3.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n152\n\n0: 384x640 12 persons, 7 handbags, 1 suitcase, 8.6ms\nSpeed: 2.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n153\n\n0: 384x640 14 persons, 5 handbags, 1 suitcase, 7.3ms\nSpeed: 2.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n154\n\n0: 384x640 18 persons, 4 handbags, 1 suitcase, 8.8ms\nSpeed: 2.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n155\n\n0: 384x640 18 persons, 5 handbags, 1 suitcase, 8.8ms\nSpeed: 2.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n156\n\n0: 384x640 13 persons, 4 handbags, 1 suitcase, 6.8ms\nSpeed: 2.8ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n157\n\n0: 384x640 17 persons, 4 handbags, 1 suitcase, 8.7ms\nSpeed: 2.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n158\n\n0: 384x640 17 persons, 4 handbags, 1 suitcase, 8.0ms\nSpeed: 2.3ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n159\n\n0: 384x640 15 persons, 3 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n160\n\n0: 384x640 19 persons, 3 handbags, 1 suitcase, 1 clock, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n161\n\n0: 384x640 13 persons, 5 handbags, 1 suitcase, 1 clock, 8.1ms\nSpeed: 2.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n162\n\n0: 384x640 15 persons, 7 handbags, 1 suitcase, 1 clock, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n163\n\n0: 384x640 15 persons, 5 handbags, 1 clock, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n164\n\n0: 384x640 18 persons, 7 handbags, 1 clock, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n165\n\n0: 384x640 20 persons, 4 handbags, 1 clock, 8.8ms\nSpeed: 2.5ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n166\n\n0: 384x640 17 persons, 5 handbags, 1 clock, 6.8ms\nSpeed: 3.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n167\n\n0: 384x640 15 persons, 2 handbags, 1 clock, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n168\n\n0: 384x640 13 persons, 4 handbags, 1 clock, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n169\n\n0: 384x640 11 persons, 4 handbags, 1 clock, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n170\n\n0: 384x640 14 persons, 3 handbags, 1 suitcase, 1 clock, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n171\n\n0: 384x640 14 persons, 4 handbags, 1 clock, 7.9ms\nSpeed: 2.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n172\n\n0: 384x640 16 persons, 7 handbags, 1 clock, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n173\n\n0: 384x640 14 persons, 6 handbags, 1 suitcase, 1 clock, 8.9ms\nSpeed: 2.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n174\n\n0: 384x640 18 persons, 4 handbags, 1 suitcase, 1 clock, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n175\n\n0: 384x640 18 persons, 3 handbags, 1 clock, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n176\n\n0: 384x640 14 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n177\n\n0: 384x640 16 persons, 2 handbags, 1 clock, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n178\n\n0: 384x640 17 persons, 1 backpack, 2 handbags, 1 clock, 7.5ms\nSpeed: 2.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n179\n\n0: 384x640 16 persons, 3 handbags, 1 clock, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n180\n\n0: 384x640 20 persons, 3 handbags, 1 suitcase, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n181\n\n0: 384x640 19 persons, 1 backpack, 3 handbags, 1 clock, 7.6ms\nSpeed: 2.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n182\n\n0: 384x640 15 persons, 2 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n183\n\n0: 384x640 16 persons, 1 backpack, 5 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n184\n\n0: 384x640 17 persons, 1 bench, 5 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n185\n\n0: 384x640 19 persons, 1 backpack, 4 handbags, 8.9ms\nSpeed: 2.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n186\n\n0: 384x640 21 persons, 1 backpack, 4 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n187\n\n0: 384x640 22 persons, 4 handbags, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n188\n\n0: 384x640 22 persons, 4 handbags, 7.2ms\nSpeed: 2.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n189\n\n0: 384x640 19 persons, 3 handbags, 1 clock, 9.0ms\nSpeed: 2.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n190\n\n0: 384x640 22 persons, 3 handbags, 7.0ms\nSpeed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n191\n\n0: 384x640 23 persons, 2 handbags, 7.3ms\nSpeed: 2.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n192\n\n0: 384x640 26 persons, 1 handbag, 7.4ms\nSpeed: 2.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n193\n\n0: 384x640 21 persons, 2 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n194\n\n0: 384x640 20 persons, 1 backpack, 3 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n195\n\n0: 384x640 18 persons, 1 handbag, 9.1ms\nSpeed: 2.6ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n196\n\n0: 384x640 19 persons, 1 bench, 1 backpack, 2 handbags, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n197\n\n0: 384x640 18 persons, 1 backpack, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n198\n\n0: 384x640 18 persons, 3 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n199\n\n0: 384x640 17 persons, 3 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n200\n\n0: 384x640 19 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n201\n\n0: 384x640 16 persons, 2 handbags, 8.3ms\nSpeed: 2.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n202\n\n0: 384x640 20 persons, 2 handbags, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n203\n\n0: 384x640 20 persons, 3 handbags, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n204\n\n0: 384x640 19 persons, 2 handbags, 7.4ms\nSpeed: 2.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n205\n\n0: 384x640 19 persons, 1 handbag, 9.5ms\nSpeed: 2.7ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n206\n\n0: 384x640 18 persons, 3 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n207\n\n0: 384x640 16 persons, 2 handbags, 1 suitcase, 7.8ms\nSpeed: 2.3ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n208\n\n0: 384x640 18 persons, 3 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n209\n\n0: 384x640 19 persons, 3 handbags, 1 suitcase, 8.2ms\nSpeed: 2.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n210\n\n0: 384x640 22 persons, 2 handbags, 1 suitcase, 7.4ms\nSpeed: 2.9ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n211\n\n0: 384x640 22 persons, 1 motorcycle, 5 handbags, 1 suitcase, 7.9ms\nSpeed: 2.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n212\n\n0: 384x640 20 persons, 4 handbags, 1 suitcase, 7.2ms\nSpeed: 3.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n213\n\n0: 384x640 22 persons, 4 handbags, 7.3ms\nSpeed: 2.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n214\n\n0: 384x640 19 persons, 2 handbags, 7.8ms\nSpeed: 2.3ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n215\n\n0: 384x640 18 persons, 3 handbags, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n216\n\n0: 384x640 19 persons, 2 handbags, 6.5ms\nSpeed: 2.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n217\n\n0: 384x640 20 persons, 4 handbags, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n218\n\n0: 384x640 16 persons, 2 handbags, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n219\n\n0: 384x640 18 persons, 2 handbags, 7.9ms\nSpeed: 2.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n220\n\n0: 384x640 19 persons, 3 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n221\n\n0: 384x640 17 persons, 3 handbags, 8.7ms\nSpeed: 2.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n222\n\n0: 384x640 17 persons, 4 handbags, 1 suitcase, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n223\n\n0: 384x640 17 persons, 3 handbags, 1 suitcase, 7.5ms\nSpeed: 3.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n224\n\n0: 384x640 18 persons, 4 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n225\n\n0: 384x640 14 persons, 4 handbags, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n226\n\n0: 384x640 15 persons, 3 handbags, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n227\n\n0: 384x640 19 persons, 2 handbags, 7.5ms\nSpeed: 2.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n228\n\n0: 384x640 21 persons, 2 handbags, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n229\n\n0: 384x640 21 persons, 2 handbags, 1 clock, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n230\n\n0: 384x640 17 persons, 5 handbags, 1 suitcase, 1 clock, 7.4ms\nSpeed: 2.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n231\n\n0: 384x640 19 persons, 5 handbags, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n232\n\n0: 384x640 22 persons, 5 handbags, 7.7ms\nSpeed: 2.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n233\n\n0: 384x640 17 persons, 5 handbags, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n234\n\n0: 384x640 18 persons, 5 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n235\n\n0: 384x640 15 persons, 5 handbags, 1 suitcase, 8.9ms\nSpeed: 2.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n236\n\n0: 384x640 14 persons, 3 handbags, 6.8ms\nSpeed: 2.9ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n237\n\n0: 384x640 13 persons, 4 handbags, 1 suitcase, 8.8ms\nSpeed: 2.6ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n238\n\n0: 384x640 16 persons, 4 handbags, 6.8ms\nSpeed: 2.8ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n239\n\n0: 384x640 17 persons, 1 handbag, 1 suitcase, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n240\n\n0: 384x640 14 persons, 5 handbags, 7.4ms\nSpeed: 2.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n241\n\n0: 384x640 18 persons, 6 handbags, 7.7ms\nSpeed: 2.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n242\n\n0: 384x640 17 persons, 4 handbags, 1 suitcase, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n243\n\n0: 384x640 19 persons, 5 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n244\n\n0: 384x640 18 persons, 6 handbags, 7.1ms\nSpeed: 2.6ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n245\n\n0: 384x640 17 persons, 5 handbags, 8.9ms\nSpeed: 2.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n246\n\n0: 384x640 16 persons, 2 handbags, 6.6ms\nSpeed: 2.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n247\n\n0: 384x640 13 persons, 3 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n248\n\n0: 384x640 14 persons, 4 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n249\n\n0: 384x640 14 persons, 3 handbags, 7.2ms\nSpeed: 2.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n250\n\n0: 384x640 14 persons, 4 handbags, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n251\n\n0: 384x640 15 persons, 3 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n252\n\n0: 384x640 14 persons, 8 handbags, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n253\n\n0: 384x640 13 persons, 5 handbags, 8.7ms\nSpeed: 2.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n254\n\n0: 384x640 15 persons, 4 handbags, 6.7ms\nSpeed: 2.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n255\n\n0: 384x640 13 persons, 4 handbags, 7.1ms\nSpeed: 2.6ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n256\n\n0: 384x640 15 persons, 2 handbags, 6.9ms\nSpeed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n257\n\n0: 384x640 15 persons, 2 handbags, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n258\n\n0: 384x640 18 persons, 5 handbags, 7.0ms\nSpeed: 2.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n259\n\n0: 384x640 19 persons, 1 motorcycle, 6 handbags, 7.2ms\nSpeed: 2.8ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n260\n\n0: 384x640 14 persons, 7 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n261\n\n0: 384x640 15 persons, 6 handbags, 9.0ms\nSpeed: 2.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n262\n\n0: 384x640 13 persons, 8 handbags, 7.7ms\nSpeed: 2.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n263\n\n0: 384x640 11 persons, 5 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n264\n\n0: 384x640 11 persons, 5 handbags, 6.9ms\nSpeed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n265\n\n0: 384x640 12 persons, 4 handbags, 7.7ms\nSpeed: 2.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n266\n\n0: 384x640 13 persons, 4 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n267\n\n0: 384x640 15 persons, 4 handbags, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n268\n\n0: 384x640 15 persons, 4 handbags, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n269\n\n0: 384x640 13 persons, 4 handbags, 9.0ms\nSpeed: 2.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n270\n\n0: 384x640 14 persons, 12.1ms\nSpeed: 2.6ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n271\n\n0: 384x640 11 persons, 3 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n272\n\n0: 384x640 10 persons, 3 handbags, 6.9ms\nSpeed: 2.9ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n273\n\n0: 384x640 11 persons, 3 handbags, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n274\n\n0: 384x640 11 persons, 2 handbags, 6.5ms\nSpeed: 2.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n275\n\n0: 384x640 11 persons, 4 handbags, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n276\n\n0: 384x640 13 persons, 2 handbags, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n277\n\n0: 384x640 15 persons, 3 handbags, 7.0ms\nSpeed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n278\n\n0: 384x640 13 persons, 6 handbags, 7.1ms\nSpeed: 2.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n279\n\n0: 384x640 12 persons, 7 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n280\n\n0: 384x640 13 persons, 5 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n281\n\n0: 384x640 11 persons, 2 backpacks, 5 handbags, 7.8ms\nSpeed: 2.9ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n282\n\n0: 384x640 11 persons, 6 handbags, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n283\n\n0: 384x640 10 persons, 1 umbrella, 2 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n284\n\n0: 384x640 11 persons, 1 handbag, 7.0ms\nSpeed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n285\n\n0: 384x640 11 persons, 1 handbag, 8.7ms\nSpeed: 2.7ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n286\n\n0: 384x640 12 persons, 1 backpack, 3 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n287\n\n0: 384x640 17 persons, 3 handbags, 7.1ms\nSpeed: 2.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n288\n\n0: 384x640 15 persons, 4 handbags, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n289\n\n0: 384x640 15 persons, 2 handbags, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n290\n\n0: 384x640 14 persons, 3 handbags, 6.9ms\nSpeed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n291\n\n0: 384x640 14 persons, 3 handbags, 7.6ms\nSpeed: 2.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n292\n\n0: 384x640 13 persons, 3 handbags, 7.1ms\nSpeed: 2.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n293\n\n0: 384x640 15 persons, 5 handbags, 9.0ms\nSpeed: 2.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n294\n\n0: 384x640 15 persons, 3 handbags, 1 potted plant, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n295\n\n0: 384x640 15 persons, 1 handbag, 7.4ms\nSpeed: 2.8ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n296\n\n0: 384x640 15 persons, 4 handbags, 8.0ms\nSpeed: 2.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n297\n\n0: 384x640 12 persons, 4 handbags, 8.4ms\nSpeed: 2.8ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n298\n\n0: 384x640 12 persons, 3 handbags, 7.2ms\nSpeed: 2.8ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n299\n\n0: 384x640 14 persons, 1 handbag, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n300\n\n0: 384x640 13 persons, 3 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n301\n\n0: 384x640 13 persons, 2 handbags, 8.6ms\nSpeed: 2.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n302\n\n0: 384x640 17 persons, 4 handbags, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n303\n\n0: 384x640 16 persons, 4 handbags, 8.5ms\nSpeed: 2.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n304\n\n0: 384x640 16 persons, 2 handbags, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n305\n\n0: 384x640 14 persons, 3 handbags, 7.7ms\nSpeed: 3.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n306\n\n0: 384x640 15 persons, 4 handbags, 7.0ms\nSpeed: 2.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n307\n\n0: 384x640 17 persons, 3 handbags, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n308\n\n0: 384x640 16 persons, 3 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n309\n\n0: 384x640 15 persons, 3 handbags, 1 suitcase, 9.0ms\nSpeed: 2.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n310\n\n0: 384x640 15 persons, 2 handbags, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n311\n\n0: 384x640 14 persons, 2 handbags, 6.5ms\nSpeed: 2.5ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n312\n\n0: 384x640 16 persons, 2 handbags, 8.2ms\nSpeed: 2.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n313\n\n0: 384x640 15 persons, 1 handbag, 9.0ms\nSpeed: 2.7ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n314\n\n0: 384x640 15 persons, 2 handbags, 1 suitcase, 6.9ms\nSpeed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n315\n\n0: 384x640 15 persons, 1 handbag, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n316\n\n0: 384x640 15 persons, 2 handbags, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n317\n\n0: 384x640 18 persons, 1 handbag, 8.7ms\nSpeed: 2.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n318\n\n0: 384x640 18 persons, 2 handbags, 7.4ms\nSpeed: 2.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n319\n\n0: 384x640 20 persons, 1 handbag, 7.5ms\nSpeed: 3.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n320\n\n0: 384x640 24 persons, 2 handbags, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n321\n\n0: 384x640 25 persons, 1 handbag, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n322\n\n0: 384x640 19 persons, 1 handbag, 6.4ms\nSpeed: 2.2ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n323\n\n0: 384x640 20 persons, 3 handbags, 9.0ms\nSpeed: 2.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n324\n\n0: 384x640 20 persons, 2 handbags, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n325\n\n0: 384x640 20 persons, 3 handbags, 8.5ms\nSpeed: 2.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n326\n\n0: 384x640 21 persons, 3 handbags, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n327\n\n0: 384x640 21 persons, 2 handbags, 8.9ms\nSpeed: 2.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n328\n\n0: 384x640 19 persons, 2 handbags, 9.4ms\nSpeed: 2.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n329\n\n0: 384x640 16 persons, 2 handbags, 8.9ms\nSpeed: 2.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n330\n\n0: 384x640 16 persons, 2 handbags, 7.9ms\nSpeed: 2.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n331\n\n0: 384x640 17 persons, 2 handbags, 7.5ms\nSpeed: 2.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n332\n\n0: 384x640 18 persons, 2 handbags, 1 suitcase, 10.3ms\nSpeed: 3.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n333\n\n0: 384x640 15 persons, 2 handbags, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n334\n\n0: 384x640 15 persons, 2 handbags, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n335\n\n0: 384x640 17 persons, 1 handbag, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n336\n\n0: 384x640 17 persons, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n337\n\n0: 384x640 17 persons, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n338\n\n0: 384x640 19 persons, 1 car, 1 handbag, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n339\n\n0: 384x640 18 persons, 1 handbag, 7.5ms\nSpeed: 2.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n340\n\n0: 384x640 16 persons, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n341\n\n0: 384x640 16 persons, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n342\n\n0: 384x640 16 persons, 1 handbag, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n343\n\n0: 384x640 18 persons, 6.9ms\nSpeed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n344\n\n0: 384x640 17 persons, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n345\n\n0: 384x640 17 persons, 7.9ms\nSpeed: 2.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n346\n\n0: 384x640 17 persons, 8.2ms\nSpeed: 2.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n347\n\n0: 384x640 19 persons, 7.3ms\nSpeed: 2.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n348\n\n0: 384x640 19 persons, 1 handbag, 7.1ms\nSpeed: 2.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n349\n\n0: 384x640 19 persons, 8.6ms\nSpeed: 2.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n350\n\n0: 384x640 18 persons, 1 handbag, 10.0ms\nSpeed: 2.2ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n351\n\n0: 384x640 17 persons, 1 handbag, 6.7ms\nSpeed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n352\n\n0: 384x640 19 persons, 1 handbag, 7.8ms\nSpeed: 2.1ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n353\n\n0: 384x640 19 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n354\n\n0: 384x640 18 persons, 1 handbag, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n355\n\n0: 384x640 21 persons, 1 handbag, 7.8ms\nSpeed: 2.4ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n356\n\n0: 384x640 24 persons, 1 handbag, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n357\n\n0: 384x640 22 persons, 1 handbag, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n358\n\n0: 384x640 20 persons, 1 handbag, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n359\n\n0: 384x640 22 persons, 1 handbag, 7.2ms\nSpeed: 2.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n360\n\n0: 384x640 21 persons, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n361\n\n0: 384x640 20 persons, 1 handbag, 8.0ms\nSpeed: 2.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n362\n\n0: 384x640 18 persons, 1 handbag, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n363\n\n0: 384x640 18 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n364\n\n0: 384x640 20 persons, 1 handbag, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n365\n\n0: 384x640 20 persons, 1 handbag, 8.5ms\nSpeed: 2.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n366\n\n0: 384x640 18 persons, 7.5ms\nSpeed: 3.0ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n367\n\n0: 384x640 16 persons, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n368\n\n0: 384x640 17 persons, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n369\n\n0: 384x640 19 persons, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n370\n\n0: 384x640 18 persons, 1 umbrella, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n371\n\n0: 384x640 17 persons, 7.3ms\nSpeed: 2.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n372\n\n0: 384x640 20 persons, 6.7ms\nSpeed: 2.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n373\n\n0: 384x640 21 persons, 6.6ms\nSpeed: 2.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n374\n\n0: 384x640 17 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n375\n\n0: 384x640 21 persons, 6.4ms\nSpeed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n376\n\n0: 384x640 19 persons, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n377\n\n0: 384x640 20 persons, 6.9ms\nSpeed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n378\n\n0: 384x640 21 persons, 6.9ms\nSpeed: 3.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n379\n\n0: 384x640 18 persons, 1 handbag, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n380\n\n0: 384x640 18 persons, 2 handbags, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n381\n\n0: 384x640 18 persons, 2 handbags, 8.4ms\nSpeed: 2.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n382\n\n0: 384x640 18 persons, 2 handbags, 6.7ms\nSpeed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n383\n\n0: 384x640 17 persons, 2 handbags, 7.1ms\nSpeed: 2.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n384\n\n0: 384x640 20 persons, 2 handbags, 7.7ms\nSpeed: 2.8ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n385\n\n0: 384x640 20 persons, 2 handbags, 7.7ms\nSpeed: 2.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n386\n\n0: 384x640 22 persons, 1 handbag, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n387\n\n0: 384x640 19 persons, 1 handbag, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n388\n\n0: 384x640 18 persons, 1 handbag, 7.0ms\nSpeed: 2.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n389\n\n0: 384x640 19 persons, 1 handbag, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n390\n\n0: 384x640 17 persons, 8.8ms\nSpeed: 2.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n391\n\n0: 384x640 16 persons, 8.2ms\nSpeed: 2.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n392\n\n0: 384x640 18 persons, 6.7ms\nSpeed: 2.7ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n393\n\n0: 384x640 18 persons, 8.1ms\nSpeed: 2.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n394\n\n0: 384x640 17 persons, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n395\n\n0: 384x640 19 persons, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n396\n\n0: 384x640 19 persons, 1 handbag, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n397\n\n0: 384x640 19 persons, 2 handbags, 8.8ms\nSpeed: 2.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n398\n\n0: 384x640 15 persons, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n399\n\n0: 384x640 18 persons, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n400\n\n0: 384x640 16 persons, 6.8ms\nSpeed: 3.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n401\n\n0: 384x640 19 persons, 9.0ms\nSpeed: 2.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n402\n\n0: 384x640 15 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n403\n\n0: 384x640 16 persons, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n404\n\n0: 384x640 16 persons, 6.6ms\nSpeed: 2.7ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n405\n\n0: 384x640 17 persons, 8.3ms\nSpeed: 2.5ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n406\n\n0: 384x640 15 persons, 1 handbag, 6.5ms\nSpeed: 2.5ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n407\n\n0: 384x640 14 persons, 1 handbag, 7.0ms\nSpeed: 2.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n408\n\n0: 384x640 14 persons, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n409\n\n0: 384x640 13 persons, 1 handbag, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n410\n\n0: 384x640 13 persons, 1 handbag, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n411\n\n0: 384x640 14 persons, 1 handbag, 6.8ms\nSpeed: 2.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n412\n\n0: 384x640 13 persons, 1 handbag, 7.7ms\nSpeed: 3.4ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n413\n\n0: 384x640 15 persons, 1 handbag, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n414\n\n0: 384x640 14 persons, 1 handbag, 6.5ms\nSpeed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n415\n\n0: 384x640 14 persons, 1 handbag, 7.4ms\nSpeed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n416\n\n0: 384x640 18 persons, 1 handbag, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n417\n\n0: 384x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n418\n\n0: 384x640 15 persons, 6.8ms\nSpeed: 2.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n419\n\n0: 384x640 13 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n420\n\n0: 384x640 13 persons, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n421\n\n0: 384x640 13 persons, 8.6ms\nSpeed: 2.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n422\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n423\n\n0: 384x640 17 persons, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n424\n\n0: 384x640 20 persons, 1 suitcase, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n425\n\n0: 384x640 18 persons, 1 suitcase, 7.5ms\nSpeed: 2.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n426\n\n0: 384x640 18 persons, 6.6ms\nSpeed: 2.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n427\n\n0: 384x640 15 persons, 8.6ms\nSpeed: 2.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n428\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n429\n\n0: 384x640 14 persons, 1 suitcase, 6.5ms\nSpeed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n430\n\n0: 384x640 13 persons, 1 suitcase, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n431\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n432\n\n0: 384x640 16 persons, 1 suitcase, 7.2ms\nSpeed: 2.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n433\n\n0: 384x640 14 persons, 1 suitcase, 8.8ms\nSpeed: 2.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n434\n\n0: 384x640 18 persons, 1 suitcase, 7.0ms\nSpeed: 2.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n435\n\n0: 384x640 16 persons, 1 suitcase, 7.4ms\nSpeed: 2.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n436\n\n0: 384x640 16 persons, 1 suitcase, 6.9ms\nSpeed: 2.9ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n437\n\n0: 384x640 14 persons, 1 suitcase, 8.5ms\nSpeed: 2.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n438\n\n0: 384x640 13 persons, 6.6ms\nSpeed: 2.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n439\n\n0: 384x640 14 persons, 1 suitcase, 7.3ms\nSpeed: 2.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n440\n\n0: 384x640 15 persons, 1 handbag, 1 suitcase, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n441\n\n0: 384x640 18 persons, 1 suitcase, 7.9ms\nSpeed: 2.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n442\n\n0: 384x640 16 persons, 1 suitcase, 6.8ms\nSpeed: 2.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n443\n\n0: 384x640 14 persons, 1 suitcase, 8.5ms\nSpeed: 2.6ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n444\n\n0: 384x640 13 persons, 1 suitcase, 6.7ms\nSpeed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n445\n\n0: 384x640 14 persons, 1 suitcase, 8.3ms\nSpeed: 2.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n446\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n447\n\n0: 384x640 14 persons, 1 handbag, 1 suitcase, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n448\n\n0: 384x640 16 persons, 1 suitcase, 7.0ms\nSpeed: 2.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n449\n\n0: 384x640 17 persons, 1 suitcase, 7.6ms\nSpeed: 2.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n450\n\n0: 384x640 16 persons, 1 suitcase, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n451\n\n0: 384x640 17 persons, 1 suitcase, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n452\n\n0: 384x640 15 persons, 1 suitcase, 6.9ms\nSpeed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n453\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n454\n\n0: 384x640 15 persons, 1 handbag, 1 suitcase, 6.6ms\nSpeed: 2.7ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n455\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n456\n\n0: 384x640 14 persons, 1 suitcase, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n457\n\n0: 384x640 17 persons, 1 handbag, 1 suitcase, 7.6ms\nSpeed: 2.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n458\n\n0: 384x640 15 persons, 1 suitcase, 1 skateboard, 7.7ms\nSpeed: 2.6ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n459\n\n0: 384x640 16 persons, 1 suitcase, 7.1ms\nSpeed: 2.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n460\n\n0: 384x640 16 persons, 1 suitcase, 8.0ms\nSpeed: 2.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n461\n\n0: 384x640 14 persons, 1 suitcase, 8.3ms\nSpeed: 2.5ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n462\n\n0: 384x640 15 persons, 6.7ms\nSpeed: 2.6ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n463\n\n0: 384x640 14 persons, 1 suitcase, 8.4ms\nSpeed: 2.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n464\n\n0: 384x640 11 persons, 2 suitcases, 6.7ms\nSpeed: 2.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n465\n\n0: 384x640 14 persons, 8.1ms\nSpeed: 3.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n466\n\n0: 384x640 12 persons, 1 suitcase, 6.8ms\nSpeed: 2.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n467\n\n0: 384x640 12 persons, 1 suitcase, 7.2ms\nSpeed: 2.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n468\n\n0: 384x640 13 persons, 6.9ms\nSpeed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n469\n\n0: 384x640 12 persons, 8.5ms\nSpeed: 2.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n470\n\n0: 384x640 12 persons, 6.7ms\nSpeed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n471\n\n0: 384x640 13 persons, 6.9ms\nSpeed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n472\n\n0: 384x640 15 persons, 1 suitcase, 6.7ms\nSpeed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n473\n\n0: 384x640 13 persons, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n474\n\n0: 384x640 14 persons, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n475\n\n0: 384x640 14 persons, 1 suitcase, 7.1ms\nSpeed: 2.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n476\n\n0: 384x640 13 persons, 1 suitcase, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n477\n\n0: 384x640 12 persons, 8.3ms\nSpeed: 2.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n478\n\n0: 384x640 15 persons, 7.1ms\nSpeed: 2.6ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n479\n\n0: 384x640 13 persons, 7.2ms\nSpeed: 2.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n480\n\n0: 384x640 17 persons, 1 suitcase, 6.6ms\nSpeed: 2.4ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n481\n\n0: 384x640 14 persons, 1 suitcase, 6.6ms\nSpeed: 2.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n482\n\n0: 384x640 18 persons, 1 suitcase, 6.7ms\nSpeed: 2.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n483\n\n0: 384x640 16 persons, 1 suitcase, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n484\n\n0: 384x640 18 persons, 1 suitcase, 6.8ms\nSpeed: 2.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n485\n\n0: 384x640 15 persons, 1 suitcase, 8.3ms\nSpeed: 2.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n486\n\n0: 384x640 16 persons, 1 suitcase, 6.8ms\nSpeed: 2.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n487\n\n0: 384x640 14 persons, 1 suitcase, 7.0ms\nSpeed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n488\n\n0: 384x640 14 persons, 1 skateboard, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n489\n\n0: 384x640 13 persons, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n490\n\n0: 384x640 14 persons, 6.7ms\nSpeed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n491\n\n0: 384x640 15 persons, 1 suitcase, 6.7ms\nSpeed: 2.8ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n492\n\n0: 384x640 17 persons, 1 suitcase, 6.5ms\nSpeed: 2.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n493\n\n0: 384x640 17 persons, 1 suitcase, 6.8ms\nSpeed: 2.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n494\n\n0: 384x640 15 persons, 1 suitcase, 6.8ms\nSpeed: 2.8ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n495\n\n0: 384x640 16 persons, 1 suitcase, 6.7ms\nSpeed: 2.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n496\n\n0: 384x640 14 persons, 1 suitcase, 6.8ms\nSpeed: 2.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n497\n\n0: 384x640 17 persons, 1 suitcase, 6.6ms\nSpeed: 2.1ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n498\n\n0: 384x640 14 persons, 1 suitcase, 6.5ms\nSpeed: 1.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n499\n\n0: 384x640 17 persons, 1 suitcase, 6.7ms\nSpeed: 1.9ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n500\n","output_type":"stream"}],"execution_count":79},{"cell_type":"markdown","source":"Any model from ultralytics can be used as detector instead of YOLO.","metadata":{}}]}